{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) <dtype: 'float32'> <dtype: 'int32'>\n",
      "tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(255.0, shape=(), dtype=float32) tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#构造一个三层的  然后使用前向传播实战  张量 直接做  使用传统的矩阵 方式\n",
    "# 后面会介绍曾方式\n",
    "# deep-learning 理解\n",
    "\n",
    "# forword.py\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "#  x [60k,28,28]\n",
    "#  y [60k]\n",
    "(x , y), _ = datasets.mnist.load_data()\n",
    "\n",
    "# x [0 - 255] - [0 - 1]\n",
    "x = tf.convert_to_tensor(x,dtype=tf.float32) / 255.\n",
    "y = tf.convert_to_tensor(y,dtype = tf.int32)\n",
    "\n",
    "print(x.shape,y.shape,x.dtype,y.dtype)\n",
    "print(tf.reduce_min(x),tf.reduce_max(x),tf.reduce_min(y),tf.reduce_max(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch (128, 28, 28) (128,)\n"
     ]
    }
   ],
   "source": [
    "#每次取128个张\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x,y)).batch(128)\n",
    "train_iter = iter(train_db)\n",
    "sample = next(train_iter)\n",
    "print('batch',sample[0].shape,sample[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss: 23747.296875\n",
      "0 100 loss: nan\n",
      "0 200 loss: nan\n",
      "0 300 loss: nan\n",
      "0 400 loss: nan\n",
      "1 0 loss: nan\n",
      "1 100 loss: nan\n",
      "1 200 loss: nan\n",
      "1 300 loss: nan\n",
      "1 400 loss: nan\n",
      "2 0 loss: nan\n",
      "2 100 loss: nan\n",
      "2 200 loss: nan\n",
      "2 300 loss: nan\n",
      "2 400 loss: nan\n",
      "3 0 loss: nan\n",
      "3 100 loss: nan\n",
      "3 200 loss: nan\n",
      "3 300 loss: nan\n",
      "3 400 loss: nan\n",
      "4 0 loss: nan\n",
      "4 100 loss: nan\n",
      "4 200 loss: nan\n",
      "4 300 loss: nan\n",
      "4 400 loss: nan\n",
      "5 0 loss: nan\n",
      "5 100 loss: nan\n",
      "5 200 loss: nan\n",
      "5 300 loss: nan\n",
      "5 400 loss: nan\n",
      "6 0 loss: nan\n",
      "6 100 loss: nan\n",
      "6 200 loss: nan\n",
      "6 300 loss: nan\n",
      "6 400 loss: nan\n",
      "7 0 loss: nan\n",
      "7 100 loss: nan\n",
      "7 200 loss: nan\n",
      "7 300 loss: nan\n",
      "7 400 loss: nan\n",
      "8 0 loss: nan\n",
      "8 100 loss: nan\n",
      "8 200 loss: nan\n",
      "8 300 loss: nan\n",
      "8 400 loss: nan\n",
      "9 0 loss: nan\n",
      "9 100 loss: nan\n",
      "9 200 loss: nan\n",
      "9 300 loss: nan\n",
      "9 400 loss: nan\n"
     ]
    }
   ],
   "source": [
    "# [b,784] => [b,521,] => [b,128] => [b,10]\n",
    "# w [dom_in,dim_out]    b [wim_out]\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784,256],stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "w2 = tf.Variable(tf.random.truncated_normal([256,128],stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([128]))\n",
    "w3 = tf.Variable(tf.random.truncated_normal([128,10],stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10]))\n",
    "# w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "# b1 = tf.Variable(tf.zeros([256]))\n",
    "# # 第二层的参数\n",
    "# w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
    "# b2 = tf.Variable(tf.zeros([128]))\n",
    "# # 第三层的参数\n",
    "# w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\n",
    "# b3 = tf.Variable(tf.zeros([10]))\n",
    "lr = 1e-3\n",
    "for epoch in range(10): #对整个数据集迭代10次\n",
    "    for step, (x, y) in enumerate(train_db): # for every batch\n",
    "        # x [128,28,28]\n",
    "        # y [128]\n",
    "        # [b,28,28] => [b,28*28]\n",
    "        x = tf.reshape(x,[-1,28*28])\n",
    "\n",
    "        with tf.GradientTape() as type:  #只会跟踪 tf.Varialbe\n",
    "            # x [b,28*28]\n",
    "            # h1 = x@w1 + b1\n",
    "            # [b,784]@[784,256] + [256] => [b,256] + [256]\n",
    "            h1 =  x@w1 + tf.broadcast_to(b1,[x.shape[0],256])\n",
    "            h1 = tf.nn.relu(h1)\n",
    "            #[b,256] => [b,128]\n",
    "            h2 =  h1 @ w2 +b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "            out = h2 @ w3 + b3\n",
    "\n",
    "            #computer loss\n",
    "            # out shape[b,10]\n",
    "            #     y [b]\n",
    "            y_onehot = tf.one_hot(y,depth = 10)\n",
    "\n",
    "            # mse = mean((y - out)^2)\n",
    "            loss = tf.square(y_onehot - out)\n",
    "            #loss = tf.square(y - out)\n",
    "            #mean : scalar\n",
    "            loss =tf.reduce_mean(loss)\n",
    "        #computr gradients\n",
    "            grads = type.gradient(loss,[w1,b1,w2,b2,w3,b3])\n",
    "        # w1 = w1 -lr * w1_grade\n",
    "        #w1.assign_sub(lr * grade[0])  #数据的类型保持不变 原地更新  都是Variable\n",
    "        w1.assign_sub(lr * grads[0])\n",
    "        b1.assign_sub(lr * grads[1])\n",
    "        w2.assign_sub(lr * grads[2])\n",
    "        b2.assign_sub(lr * grads[3])\n",
    "        w3.assign_sub(lr * grads[4])\n",
    "        b3.assign_sub(lr * grads[5])\n",
    "\n",
    "    #     w1 = w1 -lr * grade[0]\n",
    "    #     b1 = b1 -lr * grade[1]\n",
    "    #     w2 = w2 -lr * grade[2]\n",
    "    #     b2 = b2 -lr * grade[3]\n",
    "    #     w3 = w3 -lr * grade[4]\n",
    "    #     b3 = b3 -lr * grade[5]\n",
    "\n",
    "        if step % 100 ==0:\n",
    "            print(epoch,step,'loss:',float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss: 0.40986085\n",
      "0 100 loss: 0.21924451\n",
      "0 200 loss: 0.17095098\n",
      "1 0 loss: 0.16643244\n",
      "1 100 loss: 0.1639199\n",
      "1 200 loss: 0.14830378\n",
      "2 0 loss: 0.14851353\n",
      "2 100 loss: 0.14971627\n",
      "2 200 loss: 0.13586676\n",
      "3 0 loss: 0.13616422\n",
      "3 100 loss: 0.13925797\n",
      "3 200 loss: 0.12641372\n",
      "4 0 loss: 0.12668924\n",
      "4 100 loss: 0.13103408\n",
      "4 200 loss: 0.11895633\n",
      "5 0 loss: 0.1191565\n",
      "5 100 loss: 0.124378376\n",
      "5 200 loss: 0.11291341\n",
      "6 0 loss: 0.11296575\n",
      "6 100 loss: 0.118852496\n",
      "6 200 loss: 0.107912645\n",
      "7 0 loss: 0.10778787\n",
      "7 100 loss: 0.11420251\n",
      "7 200 loss: 0.103679925\n",
      "8 0 loss: 0.10338034\n",
      "8 100 loss: 0.110215224\n",
      "8 200 loss: 0.10004336\n",
      "9 0 loss: 0.09956934\n",
      "9 100 loss: 0.10673466\n",
      "9 200 loss: 0.09687663\n",
      "10 0 loss: 0.09625656\n",
      "10 100 loss: 0.10366602\n",
      "10 200 loss: 0.09409881\n",
      "11 0 loss: 0.093343414\n",
      "11 100 loss: 0.10093124\n",
      "11 200 loss: 0.091621526\n",
      "12 0 loss: 0.09076096\n",
      "12 100 loss: 0.09846982\n",
      "12 200 loss: 0.08940228\n",
      "13 0 loss: 0.088450074\n",
      "13 100 loss: 0.09623534\n",
      "13 200 loss: 0.08738344\n",
      "14 0 loss: 0.0863623\n",
      "14 100 loss: 0.09419952\n",
      "14 200 loss: 0.08553366\n",
      "15 0 loss: 0.08446029\n",
      "15 100 loss: 0.092332\n",
      "15 200 loss: 0.08382404\n",
      "16 0 loss: 0.082708865\n",
      "16 100 loss: 0.090600625\n",
      "16 200 loss: 0.08225626\n",
      "17 0 loss: 0.08108723\n",
      "17 100 loss: 0.088982664\n",
      "17 200 loss: 0.080807775\n",
      "18 0 loss: 0.0795785\n",
      "18 100 loss: 0.08747027\n",
      "18 200 loss: 0.079455435\n",
      "19 0 loss: 0.07816826\n",
      "19 100 loss: 0.08604974\n",
      "19 200 loss: 0.078189015\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.datasets as datasets\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['font.family'] = ['STKaiti']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    # 加载 MNIST 数据集\n",
    "    (x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "    # 转换为浮点张量， 并缩放到-1~1\n",
    "    x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "    # 转换为整形张量\n",
    "    y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "    # one-hot 编码\n",
    "    y = tf.one_hot(y, depth=10)\n",
    "\n",
    "    # 改变视图， [b, 28, 28] => [b, 28*28]\n",
    "    x = tf.reshape(x, (-1, 28 * 28))\n",
    "\n",
    "    # 构建数据集对象\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    # 批量训练\n",
    "    train_dataset = train_dataset.batch(200)\n",
    "    return train_dataset\n",
    "\n",
    "\n",
    "def init_paramaters():\n",
    "    # 每层的张量都需要被优化，故使用 Variable 类型，并使用截断的正太分布初始化权值张量\n",
    "    # 偏置向量初始化为 0 即可\n",
    "    # 第一层的参数\n",
    "    w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "    b1 = tf.Variable(tf.zeros([256]))\n",
    "    # 第二层的参数\n",
    "    w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
    "    b2 = tf.Variable(tf.zeros([128]))\n",
    "    # 第三层的参数\n",
    "    w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "    return w1, b1, w2, b2, w3, b3\n",
    "\n",
    "\n",
    "def train_epoch(epoch, train_dataset, w1, b1, w2, b2, w3, b3, lr=0.001):\n",
    "    for step, (x, y) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 第一层计算， [b, 784]@[784, 256] + [256] => [b, 256] + [256] => [b,256] + [b, 256]\n",
    "            h1 = x @ w1 + tf.broadcast_to(b1, (x.shape[0], 256))\n",
    "            h1 = tf.nn.relu(h1)  # 通过激活函数\n",
    "\n",
    "            # 第二层计算， [b, 256] => [b, 128]\n",
    "            h2 = h1 @ w2 + b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "            # 输出层计算， [b, 128] => [b, 10]\n",
    "            out = h2 @ w3 + b3\n",
    "\n",
    "            # 计算网络输出与标签之间的均方差， mse = mean(sum(y-out)^2)\n",
    "            # [b, 10]\n",
    "            loss = tf.square(y - out)\n",
    "            # 误差标量， mean: scalar\n",
    "            loss = tf.reduce_mean(loss)\n",
    "\n",
    "            # 自动梯度，需要求梯度的张量有[w1, b1, w2, b2, w3, b3]\n",
    "            grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
    "\n",
    "        # 梯度更新， assign_sub 将当前值减去参数值，原地更新\n",
    "        w1.assign_sub(lr * grads[0])\n",
    "        b1.assign_sub(lr * grads[1])\n",
    "        w2.assign_sub(lr * grads[2])\n",
    "        b2.assign_sub(lr * grads[3])\n",
    "        w3.assign_sub(lr * grads[4])\n",
    "        b3.assign_sub(lr * grads[5])\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(epoch, step, 'loss:', loss.numpy())\n",
    "\n",
    "    return loss.numpy()\n",
    "\n",
    "\n",
    "def train(epochs):\n",
    "    losses = []\n",
    "    train_dataset = load_data()\n",
    "    w1, b1, w2, b2, w3, b3 = init_paramaters()\n",
    "    for epoch in range(epochs):\n",
    "        loss = train_epoch(epoch, train_dataset, w1, b1, w2, b2, w3, b3, lr=0.001)\n",
    "        losses.append(loss)\n",
    "\n",
    "    x = [i for i in range(0, epochs)]\n",
    "    # 绘制曲线\n",
    "    plt.plot(x, losses, color='blue', marker='s', label='训练')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train(epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
